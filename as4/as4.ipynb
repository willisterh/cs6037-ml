{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will Hollingsworth, Colton Murray, Alexander Shiveley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_lambda = lambda x1, x2: 1 if (x1 + (3 * x2) - 2) > 0 else -1\n",
    "\n",
    "def gen_data():\n",
    "    \"\"\"\n",
    "    Generates random data points and classifies them.\n",
    "    \"\"\"\n",
    "    data = np.random.randint(low=-40, high=40, size=(100,2))\n",
    "    classification = np.array([[decision_lambda(d[0], d[1])] for d in data])\n",
    "\n",
    "    return np.hstack((data, classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sets(data, split):\n",
    "    \"\"\"\n",
    "    Convenience function that randomly selects a training and test set from the input data.\n",
    "    \n",
    "    :param data: (ndarray) the data you want to split\n",
    "    :param split: (float) the percentage of the data you want to be TRAINING data\n",
    "    \n",
    "    :returns: (tuple) a tuple where the first element is the training set, and the second element is the test set\n",
    "    \"\"\"\n",
    "    # Randomly shuffle the order from a copy of the data\n",
    "    shuffled = data.copy()\n",
    "    np.random.shuffle(shuffled)\n",
    "\n",
    "    row_count = data.shape[0]\n",
    "\n",
    "    # calc the number of samples, assumes the input samples are seperated by row\n",
    "    training_count = round(row_count * split)\n",
    "    \n",
    "    training_set = shuffled[:training_count]\n",
    "    test_set = shuffled[training_count:]\n",
    "    \n",
    "    return training_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_pos_neg(data):\n",
    "    \"\"\"\n",
    "    Returns two sets of positive, then negative examples (1's then -1's from the output column)\n",
    "    \"\"\"\n",
    "    return data[data[:, -1]==1, :-1], data[data[:, -1]==-1, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Find a balanced dataset of positive and negative samples\n",
    "ratio = -1\n",
    "while ratio == -1 or abs(1 - ratio) > 0.1:\n",
    "    data = gen_data()\n",
    "    pos, neg = split_pos_neg(data)\n",
    "\n",
    "    # Check ratio of positive and negative samples\n",
    "    ratio = len(pos) / len(neg)\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron (2 Input Linear Unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_unit():\n",
    "    def __init__(self, num_inputs):\n",
    "        self.weights = np.random.rand(num_inputs + 1)\n",
    "        \n",
    "    def output(self, data_point):\n",
    "        \"\"\"\n",
    "        Returns the linear combination of the input and this unit's weights\n",
    "        \"\"\"\n",
    "        # total = w0*1 + w1x1 + w2x2 + ...\n",
    "        data_with_bias = np.hstack((np.array([1]), data_point[:-1]))\n",
    "        t = data_with_bias * self.weights\n",
    "        t = np.sum(t)\n",
    "        \n",
    "        return t\n",
    "        \n",
    "    def delta_rule(self, learning_rate, epochs ):\n",
    "        \"\"\"\n",
    "        Performs the delta rule training for a given number of epochs\n",
    "        \"\"\"\n",
    "        # From NN_MitchelChapter4-1.pdf on canvas          \n",
    "        for ep in range(epochs): \n",
    "            delta_w = np.zeros(self.weights.shape[0])\n",
    "            for d in data:\n",
    "                d_with_bias = np.hstack((np.array([1]), d[:-1]))\n",
    "                delta_w = delta_w + learning_rate * (d[2] - self.output(d)) * d_with_bias     \n",
    "            self.weights = self.weights + delta_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = linear_unit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-31  -4  -1]\n",
      "[0.03801704 0.49188861 0.54372551]\n",
      "-17.385431935601428\n",
      "[-2.65149965e+41  4.04923959e+43 -4.10339795e+43]\n",
      "-1.09139350566825e+45\n"
     ]
    }
   ],
   "source": [
    "print(data[0])\n",
    "print(p.weights)\n",
    "print(p.output(data[0]))\n",
    "\n",
    "# Train perceptron\n",
    "p.delta_rule(0.001, 25)\n",
    "print(p.weights)\n",
    "print(p.output(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta Rule may not be working yet? weights go to high extremes.\n",
    "# I think optimal weights should approach [-2, 1, 3]. or it gets stu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
