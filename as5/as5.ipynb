{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will Hollingsworth, Colton Murray, Alexander Shiveley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699,   0.     ],\n",
       "       [  4.5459 ,   8.1674 ,  -2.4586 ,  -1.4621 ,   0.     ],\n",
       "       [  3.866  ,  -2.6383 ,   1.9242 ,   0.10645,   0.     ],\n",
       "       ...,\n",
       "       [ -3.7503 , -13.4586 ,  17.5932 ,  -2.7771 ,   1.     ],\n",
       "       [ -3.5637 ,  -8.3827 ,  12.393  ,  -1.2823 ,   1.     ],\n",
       "       [ -2.5419 ,  -0.65804,   2.6842 ,   1.1952 ,   1.     ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the csv as a numpy array of strings, \n",
    "# because it includes the column headers\n",
    "raw_data = np.loadtxt('data_banknote_authentication.txt', delimiter=',', dtype=str)\n",
    "\n",
    "# Convert everything into floats!\n",
    "clean_data = np.array(raw_data, dtype=float)\n",
    "\n",
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sets(data, split):\n",
    "    \"\"\"\n",
    "    Convenience function that randomly selects a training and test set from the input data.\n",
    "    \n",
    "    :param data: (ndarray) the data you want to split\n",
    "    :param split: (float array) the percentages of the data you want to be TRAINING, VALIDATION, and TESTING data\n",
    "    \n",
    "    :returns: (tuple) a tuple where the first element is the training set, and the second element is the test set\n",
    "    \"\"\"\n",
    "    # Randomly shuffle the order from a copy of the data\n",
    "    shuffled = data.copy()\n",
    "    np.random.shuffle(shuffled)\n",
    "\n",
    "    row_count = data.shape[0]\n",
    "\n",
    "    # calc the number of samples, assumes the input samples are seperated by row\n",
    "    training_count = round(row_count * split[0])\n",
    "    \n",
    "    training_set = shuffled[:training_count]\n",
    "    remaining_set = shuffled[training_count:]\n",
    "    \n",
    "    # calc the number of samples, assumes the input samples are seperated by row\n",
    "    training_count = round(row_count * split[1] / (split[1] + split[2]))\n",
    "    \n",
    "    validation_set = remaining_set[:training_count]\n",
    "    test_set = remaining_set[training_count:]\n",
    "    \n",
    "    return training_set, validation_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation, test = get_sets(clean_data, [1/3, 1/3, 1/3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron (2 Input Linear Unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_unit():\n",
    "    def __init__(self, num_inputs):\n",
    "        self.weights = np.random.rand(num_inputs + 1)\n",
    "        \n",
    "    def output(self, data_point):\n",
    "        \"\"\"\n",
    "        Returns the linear combination of the input and this unit's weights\n",
    "        \"\"\"\n",
    "        # total = w0*1 + w1x1 + w2x2 + ...\n",
    "        data_with_bias = np.hstack((np.array([1]), data_point[:-1]))\n",
    "        t = data_with_bias * self.weights\n",
    "        t = np.sum(t)\n",
    "        \n",
    "        return t     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_net():\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs, squash_f, squash_d_f):\n",
    "        self.hidden_units = []\n",
    "        for _ in range(num_hidden):\n",
    "            self.hidden_units.append(linear_unit(num_inputs))\n",
    "        self.output_units = []\n",
    "        for _ in range(num_outputs):\n",
    "            self.output_units.append(linear_unit(num_hidden))\n",
    "        self.squash_fn = squash_f\n",
    "        self.squash_d_fn = squash_d_f    \n",
    "        \n",
    "    def output(self, data_point):\n",
    "        \"\"\"\n",
    "        Returns the array of outputs from the output units\n",
    "        \"\"\"            \n",
    "        \n",
    "        return self.output_at_layer(data_point, 1)\n",
    "    \n",
    "    def output_data_set(self, data_set, normalize=False):\n",
    "        \"\"\"\n",
    "        Returns the array of outputs from the output units for an entire data set\n",
    "        normalize - Set output to 0 or 1\n",
    "        \"\"\"            \n",
    "        y_matrix = np.empty((data_set.shape[0], 1))\n",
    "        for row in range(data_set.shape[0]):\n",
    "            y_matrix[row, 0] = self.output(data_set[row, :])\n",
    "            if normalize:\n",
    "                y_matrix[row, 0] = 1 if y_matrix[row, 0] > 0 else 0                \n",
    "        return y_matrix\n",
    "    \n",
    "    def output_at_layer(self, data_point, layer):\n",
    "        \n",
    "        \"\"\"\n",
    "        Returns the array of outputs from the units on the specified layer\n",
    "        0 - hidden\n",
    "        1 - output\n",
    "        \"\"\"\n",
    "        ## Calculate squashed hidden outputs, with bias\n",
    "        hidden_out = [1]\n",
    "        for unit in self.hidden_units:\n",
    "            hidden_out.append(self.squash_fn(unit.output(data_point)))\n",
    "        \n",
    "        if layer == 0:\n",
    "            return np.array(hidden_out)\n",
    "            \n",
    "        ## Calculate squashed outputs using hidden outputs\n",
    "        out = []\n",
    "        for unit in self.output_units:\n",
    "            out.append(self.squash_fn(unit.output(hidden_out)))    \n",
    "            \n",
    "        return np.array(out)\n",
    "        \n",
    "        \n",
    "    def error(self, data):\n",
    "        \"\"\"\n",
    "        Returns the sum squared error of the data using this network's output units\n",
    "        \"\"\"\n",
    "        sum = 0\n",
    "        for d in data:\n",
    "            # Only 1 output is handled is supported\n",
    "            o = self.output(d)[0]\n",
    "            sum = sum + (d[2] - o)**2\n",
    "        return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squashing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(x):    \n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Sigmoid derivative function\n",
    "def sigmoid_d(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# Hyperbolic tan function\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "# Hyperbolic tan derivative function\n",
    "def tanh_d(x):\n",
    "    return 1 - tanh(x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.0127 10.1477 -3.9366 -4.0728  0.    ]\n",
      "[0.73643841]\n",
      "8979.864952856784\n"
     ]
    }
   ],
   "source": [
    "net = neural_net(4, 4, 1, sigmoid, sigmoid_d)\n",
    "print(training[0])\n",
    "print(net.output(training[0]))\n",
    "print(net.error(training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(squash_f, squash_d_f, learning_rate, epochs, hidden_count):    \n",
    "    \"\"\"\n",
    "    Train the network with the specified number of hidden units using backpropagation\n",
    "    \"\"\"\n",
    "    # Step 1 Initialize network\n",
    "    network = neural_net(4, hidden_count, 1, squash_f, squash_d_f)\n",
    "\n",
    "    # TODO Train network and do the backpropagation\n",
    "    # From NN-MitchelChapter4-2 on canvas\n",
    "    # Alex - Started on it but need to be careful with tanh. The notes on canvas works out sigmoid in detail but not tanh\n",
    "    #           Using a more generalized form of the equations for the algorithm in 1.2\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for d in training:\n",
    "            d_with_bias = np.hstack((np.array([1]), d[:-1]))\n",
    "            hidden_out = network.output_at_layer(d, 0)\n",
    "\n",
    "            # Step 2 but relacing specific sigmoid derivative with the squash derivative\n",
    "            delta_out = []\n",
    "            for k in range(len(network.output_units)):\n",
    "                unit = network.output_units[k]\n",
    "                unit_out = unit.output(hidden_out)\n",
    "                unit_delta = squash_d_f(unit_out) * (d[4] - squash_f(unit_out))\n",
    "                delta_out.append(unit_delta)\n",
    "\n",
    "            # Step 3 but replacing specific sigmoid derivative with the squash derivative\n",
    "            delta_hidden = []\n",
    "            for h in range(len(network.hidden_units)):\n",
    "                unit = network.hidden_units[h]\n",
    "                unit_out = unit.output(d_with_bias)\n",
    "                sum_value = np.sum([network.output_units[k].weights[1 + h] * delta_out[k] for k in range(len(network.output_units))])\n",
    "                unit_delta = squash_d_f(unit_out) * sum_value\n",
    "                delta_hidden.append(unit_delta)\n",
    "\n",
    "            # Step 4 update weights\n",
    "            for k in range(len(network.output_units)):\n",
    "                delta_w = learning_rate * delta_out[k] * hidden_out\n",
    "                network.output_units[k].weights = network.output_units[k].weights + delta_w\n",
    "\n",
    "            for h in range(len(network.hidden_units)):\n",
    "                delta_w = learning_rate * delta_hidden[h] * d_with_bias\n",
    "                network.hidden_units[h].weights = network.hidden_units[h].weights + delta_w\n",
    "                \n",
    "            \n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Best Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 1\n",
      "Validation Error: 13924.096046809898\n",
      "Test Error: 3499.240848489562\n",
      "\n",
      "Hidden Layer Size: 2\n",
      "Validation Error: 15035.406582011077\n",
      "Test Error: 3784.166606735133\n",
      "\n",
      "Hidden Layer Size: 3\n",
      "Validation Error: 14899.737733952168\n",
      "Test Error: 3748.631548865207\n",
      "\n",
      "Hidden Layer Size: 4\n",
      "Validation Error: 13116.749477584768\n",
      "Test Error: 3263.1874979336235\n",
      "\n",
      "Best Network Hidden Layer Size Based on Validation Error: 4\n"
     ]
    }
   ],
   "source": [
    "# TODO Need to select learning rate and epochs\n",
    "sigmoid_networks = []\n",
    "sigmoid_best_network = None\n",
    "for h in range(1, 5):\n",
    "    net = backpropagation(sigmoid, sigmoid_d, 0.01, 50, h)\n",
    "    sigmoid_networks.append(net)\n",
    "    \n",
    "    # If this network has lower error from validation set, set as best\n",
    "    if sigmoid_best_network is None or net.error(validation) < sigmoid_best_network.error(validation):\n",
    "        sigmoid_best_network = net\n",
    "    \n",
    "    print(\"Hidden Layer Size:\", len(net.hidden_units))\n",
    "    print(\"Validation Error:\", net.error(validation))\n",
    "    print(\"Test Error:\", net.error(test))\n",
    "    print()\n",
    "\n",
    "print(\"Best Network Hidden Layer Size Based on Validation Error:\", len(sigmoid_best_network.hidden_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tanh Best Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 1\n",
      "Validation Error: 14235.298782375596\n",
      "Test Error: 3566.1140289737814\n",
      "\n",
      "Hidden Layer Size: 2\n",
      "Validation Error: 12366.059638921024\n",
      "Test Error: 3065.099065346224\n",
      "\n",
      "Hidden Layer Size: 3\n",
      "Validation Error: 14130.677630905366\n",
      "Test Error: 3624.924249513831\n",
      "\n",
      "Hidden Layer Size: 4\n",
      "Validation Error: 14048.260493059086\n",
      "Test Error: 3591.024936378486\n",
      "\n",
      "Best Network Hidden Layer Size Based on Validation Error: 2\n"
     ]
    }
   ],
   "source": [
    "# TODO Need to select learning rate and epochs\n",
    "# Alex - There was a discussion question on canvas related to tanh. Do we need to scale tanh to [0, 1] or is [-1, 1] ok?\n",
    "tanh_networks = []\n",
    "tanh_best_network = None\n",
    "for h in range(1, 5):\n",
    "    net = backpropagation(tanh, tanh_d, 0.01, 50, h)\n",
    "    tanh_networks.append(net)\n",
    "    \n",
    "    # If this network has lower error from validation set, set as best\n",
    "    if tanh_best_network is None or net.error(validation) < tanh_best_network.error(validation):\n",
    "        tanh_best_network = net\n",
    "    \n",
    "    print(\"Hidden Layer Size:\", len(net.hidden_units))\n",
    "    print(\"Validation Error:\", net.error(validation))\n",
    "    print(\"Test Error:\", net.error(test))\n",
    "    print()\n",
    "\n",
    "print(\"Best Network Hidden Layer Size Based on Validation Error:\", len(tanh_best_network.hidden_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(classified, test):\n",
    "    comp = (classified[:, -1] == test[:, -1])\n",
    "    return np.count_nonzero(comp) / len(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid Best Network Accuracy: 0.4279475982532751\n",
      "tanh Best Network Accuracy: 0.4279475982532751\n"
     ]
    }
   ],
   "source": [
    "print(\"Sigmoid Best Network Accuracy:\", accuracy(sigmoid_best_network.output_data_set(test, True), test))\n",
    "print(\"tanh Best Network Accuracy:\", accuracy(tanh_best_network.output_data_set(test, True), test))\n",
    "\n",
    "# Alex - Something doesn't feel right, especially looking at the low accuracy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
